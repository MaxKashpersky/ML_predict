"""
–ú–æ–¥—É–ª—å –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from config import config
from modules.database import Database
from modules.predictor import SignalPredictor
from modules.preprocessor import DataPreprocessor
from modules.state_manager import state_manager


class Backtester:
    def __init__(self, verbose: bool = True):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—ç–∫—Ç–µ—Å—Ç–µ—Ä–∞"""
        self.verbose = verbose
        self.setup_logging()
        self.db = Database(verbose=verbose)
        self.predictor = SignalPredictor(verbose=verbose)
        self.preprocessor = DataPreprocessor(verbose=verbose)
        self.state_manager = state_manager

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.initial_balance = config.backtest.INITIAL_BALANCE
        self.commission = config.trading.COMMISSION
        self.stop_loss_pct = config.trading.STOP_LOSS_PCT / 100
        self.take_profit_pct = config.trading.TAKE_PROFIT_PCT / 100
        self.slippage = getattr(config.backtest, 'SLIPPAGE', 0.0005)

    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        self.logger = logging.getLogger(__name__)
        if self.verbose:
            self.logger.setLevel(logging.INFO)
        else:
            self.logger.setLevel(logging.WARNING)

    def log(self, message: str, level: str = 'info'):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        if self.verbose:
            if level == 'info':
                self.logger.info(message)
            elif level == 'error':
                self.logger.error(message)
            elif level == 'warning':
                self.logger.warning(message)

    def get_best_model(self, symbol: str, model_id: Optional[str] = None, verbose: bool = True) -> Tuple[Any, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –∏–ª–∏ —É–∫–∞–∑–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        """
        try:
            from modules.trainer import ModelTrainer
            trainer = ModelTrainer(verbose=verbose)

            if model_id:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∫–∞–∑–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
                model, scaler = trainer.load_model(model_id, verbose=verbose)
                if model:
                    return model, scaler
                else:
                    self.log(f"Failed to load specified model {model_id}", 'warning')

            # –ò—â–µ–º –ª—É—á—à—É—é –∞–∫—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å
            models_df = self.db.get_available_models(
                symbol=symbol,
                active_only=True,
                verbose=verbose
            )

            if models_df.empty:
                self.log(f"No active models found for {symbol}", 'warning')
                return None, None

            # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å —Å –ª—É—á—à–µ–π accuracy
            best_model_row = None
            best_accuracy = -1

            for _, row in models_df.iterrows():
                try:
                    metrics = row['metrics']
                    if isinstance(metrics, str):
                        import json
                        metrics = json.loads(metrics)

                    accuracy = metrics.get('accuracy', metrics.get('val_accuracy', 0))
                    if accuracy > best_accuracy:
                        best_accuracy = accuracy
                        best_model_row = row
                except:
                    continue

            if best_model_row is None:
                self.log(f"No models with valid metrics for {symbol}", 'warning')
                return None, None

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            model, scaler = trainer.load_model(best_model_row['model_id'], verbose=verbose)
            return model, scaler

        except Exception as e:
            self.log(f"Error getting best model: {str(e)}", 'error')
            return None, None

    def prepare_backtest_data(self, data: pd.DataFrame, model_type: str, verbose: bool = True) -> pd.DataFrame:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞
        """
        try:
            if data.empty:
                return pd.DataFrame()

            if verbose:
                print(f"  üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(data)} —Å—Ç—Ä–æ–∫, {len(data.columns)} –∫–æ–ª–æ–Ω–æ–∫")

            # –†–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            data_with_indicators = self.preprocessor.calculate_all_indicators(
                data, verbose=verbose
            )

            if data_with_indicators.empty:
                self.log("Failed to calculate indicators", 'warning')
                return pd.DataFrame()

            if verbose:
                print(
                    f"  üìà –î–∞–Ω–Ω—ã–µ —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏: {len(data_with_indicators)} —Å—Ç—Ä–æ–∫, {len(data_with_indicators.columns)} –∫–æ–ª–æ–Ω–æ–∫")
                print(f"  üî§ –ü—Ä–∏–º–µ—Ä –∫–æ–ª–æ–Ω–æ–∫: {list(data_with_indicators.columns[:10])}...")

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ –µ—Å–ª–∏ —ç—Ç–æ LSTM –º–æ–¥–µ–ª—å
            if 'lstm' in model_type.lower():
                data_with_indicators = self.preprocessor.add_advanced_features(
                    data_with_indicators, verbose=verbose
                )

                if verbose:
                    print(
                        f"  üîß –î–æ–±–∞–≤–ª–µ–Ω—ã —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏: {len(data_with_indicators)} —Å—Ç—Ä–æ–∫, {len(data_with_indicators.columns)} –∫–æ–ª–æ–Ω–æ–∫")

            return data_with_indicators

        except Exception as e:
            self.log(f"Error preparing backtest data: {str(e)}", 'error')
            return pd.DataFrame()

    def generate_backtest_signals(self, data: pd.DataFrame, model: Any, scaler: Any,
                                  model_type: str, verbose: bool = True) -> pd.DataFrame:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞
        """
        try:
            if data.empty or model is None:
                return pd.DataFrame()

            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤
            signals_df = data.copy()
            signals_df['signal'] = 0  # 0 = HOLD, 1 = LONG, -1 = SHORT
            signals_df['confidence'] = 0.0
            signals_df['prediction_time'] = signals_df.index

            # –ü–æ–ª—É—á–∞–µ–º lookback_window –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
            lookback_window = config.model.LOOKBACK_WINDOW

            # –ü–æ–ª—É—á–∞–µ–º feature_names –∏–∑ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            feature_names = None
            if hasattr(model, 'feature_names'):
                feature_names = model.feature_names
            elif hasattr(model, 'base_feature_names'):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ –∏–º–µ–Ω–∞ —Ñ–∏—á–µ–π –¥–ª—è XGBoost
                feature_names = model.base_feature_names

            # –ï—Å–ª–∏ –Ω–µ—Ç feature_names, –ø–æ–ª—É—á–∞–µ–º –∏—Ö –∏–∑ –¥–∞–Ω–Ω—ã—Ö
            if feature_names is None:
                feature_names = [col for col in data.columns
                                 if not col.startswith('TARGET_')
                                 and col not in ['signal', 'confidence', 'prediction_time']
                                 and pd.api.types.is_numeric_dtype(data[col])]

            # –î–ª—è XGBoost –Ω–∞–º –Ω—É–∂–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ñ–∏—á–∏
            if 'xgb' in model_type.lower():
                # –î–ª—è XGBoost, –∫–æ—Ç–æ—Ä—ã–π –æ–±—É—á–∞–ª—Å—è –Ω–∞ 2D –¥–∞–Ω–Ω—ã—Ö (lookback_window * features)
                expected_features = lookback_window * len(feature_names)
            else:
                expected_features = len(feature_names)

            for i in range(lookback_window, len(signals_df)):
                try:
                    # –ë–µ—Ä–µ–º –æ–∫–Ω–æ –¥–∞–Ω–Ω—ã—Ö
                    window_data = signals_df.iloc[i - lookback_window:i]

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É –Ω–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ñ–∏—á–µ–π
                    available_features = [col for col in feature_names if col in window_data.columns]

                    if len(available_features) != len(feature_names):
                        if verbose and i == lookback_window:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –æ–∫–Ω–∞
                            self.log(f"Feature mismatch: expected {len(feature_names)}, got {len(available_features)}",
                                     'warning')
                        continue

                    # –ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                    X_window = window_data[available_features].values

                    # –î–ª—è XGBoost –Ω—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ 2D
                    if 'xgb' in model_type.lower():
                        X_window_flat = X_window.flatten().reshape(1, -1)

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
                        if X_window_flat.shape[1] != expected_features:
                            if verbose and i == lookback_window:
                                self.log(
                                    f"XGBoost feature shape mismatch: expected {expected_features}, got {X_window_flat.shape[1]}",
                                    'warning')
                                self.log(f"Lookback: {lookback_window}, Features: {len(feature_names)}", 'warning')
                            continue

                        X_window_final = X_window_flat
                    else:
                        # –î–ª—è LSTM –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å (3D)
                        X_window_final = X_window.reshape(1, lookback_window, -1)

                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –µ—Å–ª–∏ –µ—Å—Ç—å —Å–∫–µ–π–ª–µ—Ä
                    if scaler is not None:
                        try:
                            if 'xgb' in model_type.lower():
                                X_window_norm = scaler.transform(X_window_final)
                            else:
                                X_window_norm = scaler.transform(X_window_final.reshape(1, -1)).reshape(1,
                                                                                                        lookback_window,
                                                                                                        -1)
                        except Exception as e:
                            if verbose and i == lookback_window:
                                self.log(f"Normalization error: {str(e)}", 'warning')
                            X_window_norm = X_window_final
                    else:
                        X_window_norm = X_window_final

                    # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    if hasattr(model, 'predict'):
                        prediction = model.predict(X_window_norm)

                        if 'lstm' in model_type.lower():
                            # LSTM –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
                            if len(prediction.shape) == 2:
                                predicted_class = np.argmax(prediction[0]) - 1  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º [0,1,2] -> [-1,0,1]
                                confidence = np.max(prediction[0])
                            else:
                                predicted_class = int(prediction[0]) - 1
                                confidence = 0.5
                        else:
                            # XGBoost –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–ª–∞—Å—Å—ã
                            predicted_class = int(prediction[0]) - 1
                            confidence = 0.5

                        signals_df.iloc[i, signals_df.columns.get_loc('signal')] = predicted_class
                        signals_df.iloc[i, signals_df.columns.get_loc('confidence')] = confidence

                except Exception as e:
                    if verbose and i == lookback_window:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –æ–∫–Ω–∞
                        self.log(f"Error generating signal at index {i}: {str(e)}", 'warning')
                    continue

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å —Å–∏–≥–Ω–∞–ª–∞–º–∏
            signals_with_data = signals_df[signals_df['signal'] != 0].copy()

            if verbose:
                self.log(f"Generated {len(signals_with_data)} signals")

            return signals_with_data

        except Exception as e:
            self.log(f"Error generating backtest signals: {str(e)}", 'error')
            return pd.DataFrame()

    def generate_backtest_signals_simple(self, data: pd.DataFrame, model: Any, scaler: Any,
                                         model_type: str, verbose: bool = True) -> pd.DataFrame:
        """
        –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞
        """
        try:
            if data.empty or model is None:
                return pd.DataFrame()

            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤
            signals_df = data.copy()
            signals_df['signal'] = 0
            signals_df['confidence'] = 0.0

            # –ü–æ–ª—É—á–∞–µ–º lookback_window –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
            lookback_window = config.model.LOOKBACK_WINDOW

            # –í–ê–ñ–ù–û: –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ —Ñ–∏—á–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
            # –°–ø–æ—Å–æ–± 1: –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏ –∏–∑ –º–æ–¥–µ–ª–∏
            base_feature_columns = None

            if hasattr(model, 'base_feature_names'):
                base_feature_columns = model.base_feature_names
                if verbose:
                    print(f"  üìã –ë–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏ –∏–∑ –º–æ–¥–µ–ª–∏: {len(base_feature_columns)} —Ñ–∏—á–µ–π")
                    print(f"  üìã –ë–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏: {base_feature_columns}")
            elif hasattr(model, 'feature_names'):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è—é—Ç—Å—è –ª–∏ —Ñ–∏—á–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏
                feature_names = model.feature_names
                if isinstance(feature_names, list) and len(feature_names) > 0:
                    # –ï—Å–ª–∏ —Ñ–∏—á–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ª–∞–≥–∏ - —ç—Ç–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏
                    if any('_t-' in str(feature) for feature in feature_names[:10]):
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏ –∏–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö
                        base_features = set()
                        for feature in feature_names:
                            if isinstance(feature, str) and '_t-' in feature:
                                base_feature = feature.split('_t-')[0]
                                base_features.add(base_feature)
                            else:
                                base_features.add(str(feature))
                        base_feature_columns = list(base_features)
                        if verbose:
                            print(f"  üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ –≤ –º–æ–¥–µ–ª–∏")
                            print(f"  üîÑ –ò–∑–≤–ª–µ—á–µ–Ω–æ –±–∞–∑–æ–≤—ã—Ö —Ñ–∏—á–µ–π: {len(base_feature_columns)}")
                    else:
                        # –ï—Å–ª–∏ –Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ª–∞–≥–æ–≤ - —ç—Ç–æ –±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏
                        base_feature_columns = feature_names
                        if verbose:
                            print(f"  üìã –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ñ–∏—á–∏ –∏–∑ –º–æ–¥–µ–ª–∏ –∫–∞–∫ –±–∞–∑–æ–≤—ã–µ: {len(base_feature_columns)} —Ñ–∏—á–µ–π")

            # –°–ø–æ—Å–æ–± 2: –ï—Å–ª–∏ —Ñ–∏—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –Ω–∞–±–æ—Ä
            if base_feature_columns is None:
                # –ë–∞–∑–æ–≤—ã–π –Ω–∞–±–æ—Ä —Ñ–∏—á–µ–π (–∫–∞–∫ –≤ trainer.py)
                base_features = ['close', 'volume', 'returns']

                # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                tech_indicators = [col for col in data.columns
                                   if any(indicator in col.lower() for indicator in
                                          ['sma', 'ema', 'rsi', 'macd', 'bb', 'atr', 'obv', 'adx'])]

                base_feature_columns = base_features + tech_indicators

                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≤ –¥–∞–Ω–Ω—ã—Ö
                base_feature_columns = [col for col in base_feature_columns if col in data.columns]

                if verbose:
                    print(
                        f"  ‚ö†Ô∏è  –§–∏—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –º–æ–¥–µ–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –Ω–∞–±–æ—Ä: {len(base_feature_columns)} —Ñ–∏—á–µ–π")

            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ –±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
            missing_features = []
            for feature in base_feature_columns:
                if feature not in signals_df.columns:
                    missing_features.append(feature)

            if missing_features:
                if verbose:
                    print(f"  ‚ö†Ô∏è  –°–æ–∑–¥–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏: {len(missing_features)} —Ñ–∏—á–µ–π")
                for feature in missing_features:
                    signals_df[feature] = 0.0

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –±–∞–∑–æ–≤—ã—Ö —Ñ–∏—á–µ–π —Ç–æ–ª—å–∫–æ —Ç–µ–º–∏, —á—Ç–æ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
            base_feature_columns = [col for col in base_feature_columns if col in signals_df.columns]
            base_feature_columns = sorted(base_feature_columns)  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è consistency

            if verbose:
                print(f"  üîç –ë–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏ –¥–ª—è XGBoost: {len(base_feature_columns)} —Ñ–∏—á–µ–π")
                print(f"  üìä –ë–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏: {base_feature_columns}")
                print(f"  üìê Lookback window: {lookback_window}")
                print(f"  ü§ñ –¢–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")

                # –í—ã—á–∏—Å–ª—è–µ–º –æ–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π
                expected_features = len(base_feature_columns) * lookback_window
                print(f"  üî¢ –û–∂–∏–¥–∞–µ—Ç—Å—è XGBoost —Ñ–∏—á–µ–π: {expected_features} (–±–∞–∑–æ–≤—ã–µ √ó lookback)")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–µ–π–ª–µ—Ä
                if scaler is not None and hasattr(scaler, 'n_features_in_'):
                    print(f"  üî¢ –°–∫–µ–π–ª–µ—Ä –æ–∂–∏–¥–∞–µ—Ç: {scaler.n_features_in_} —Ñ–∏—á–µ–π")
                    if scaler.n_features_in_ != expected_features:
                        print(
                            f"  ‚ö†Ô∏è  –ù–ï–°–û–í–ü–ê–î–ï–ù–ò–ï! –°–∫–µ–π–ª–µ—Ä –æ–∂–∏–¥–∞–µ—Ç {scaler.n_features_in_}, –∞ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å {expected_features}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ —Ñ–∏—á–µ–π
            if len(base_feature_columns) == 0:
                print(f"  ‚ùå –ù–µ—Ç –±–∞–∑–æ–≤—ã—Ö —Ñ–∏—á–µ–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
                return pd.DataFrame()

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
            signals_generated = 0

            for i in range(lookback_window, len(signals_df)):
                try:
                    # –ë–µ—Ä–µ–º –æ–∫–Ω–æ –¥–∞–Ω–Ω—ã—Ö
                    window_data = signals_df.iloc[i - lookback_window:i]

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É –Ω–∞—Å –≤—Å–µ –Ω—É–∂–Ω—ã–µ –±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏
                    available_features = [col for col in base_feature_columns if col in window_data.columns]
                    if len(available_features) != len(base_feature_columns):
                        if verbose and i == lookback_window:
                            print(
                                f"  ‚ö†Ô∏è  –ù–µ –≤—Å–µ –±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏ –¥–æ—Å—Ç—É–ø–Ω—ã: {len(available_features)} –∏–∑ {len(base_feature_columns)}")
                        continue

                    # –ì–æ—Ç–æ–≤–∏–º X –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è - –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ß–ê–°–¢–¨!
                    X_window = window_data[base_feature_columns].values

                    # –î–ª—è XGBoost –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ 2D —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º
                    if 'xgb' in model_type.lower():
                        # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: (lookback_window, –±–∞–∑–æ–≤—ã–µ_—Ñ–∏—á–∏) -> (1, lookback_window √ó –±–∞–∑–æ–≤—ã–µ_—Ñ–∏—á–∏)
                        X_window_flat = X_window.flatten().reshape(1, -1)

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
                        expected_shape = len(base_feature_columns) * lookback_window
                        actual_shape = X_window_flat.shape[1]

                        if verbose and i == lookback_window:
                            print(f"  üìä –û–∫–Ω–æ –¥–∞–Ω–Ω—ã—Ö shape: {X_window.shape}")
                            print(f"  üìä –ü–æ—Å–ª–µ flatten: {X_window_flat.shape}")
                            print(f"  üîç –û–∂–∏–¥–∞–µ—Ç—Å—è: {expected_shape}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_shape}")

                        if actual_shape != expected_shape:
                            if verbose and i == lookback_window:
                                print(f"  ‚ùå –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: {actual_shape} != {expected_shape}")
                                print(f"     –ë–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏: {len(base_feature_columns)}, lookback: {lookback_window}")
                            continue

                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –µ—Å–ª–∏ –µ—Å—Ç—å —Å–∫–µ–π–ª–µ—Ä
                        if scaler is not None:
                            try:
                                # –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–∫–µ–π–ª–µ—Ä –æ–∂–∏–¥–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π
                                if hasattr(scaler, 'n_features_in_') and scaler.n_features_in_ != actual_shape:
                                    if verbose and i == lookback_window:
                                        print(
                                            f"  ‚ö†Ô∏è  –°–∫–µ–π–ª–µ—Ä –æ–∂–∏–¥–∞–µ—Ç {scaler.n_features_in_} —Ñ–∏—á–µ–π, –∞ –ø–æ–ª—É—á–∏–ª–∏ {actual_shape}")
                                        print(f"  ‚ö†Ô∏è  –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∫–µ–π–ª–µ—Ä, –Ω–æ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—à–∏–±–∫–∏...")

                                X_window_norm = scaler.transform(X_window_flat)
                                if verbose and i == lookback_window:
                                    print(f"  ‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
                            except Exception as scaler_error:
                                if verbose and i == lookback_window:
                                    print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {scaler_error}")
                                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
                                X_window_norm = X_window_flat
                        else:
                            X_window_norm = X_window_flat

                        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                        try:
                            prediction = model.predict(X_window_norm)
                            predicted_class = int(prediction[0]) - 1  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º [0,1,2] -> [-1,0,1]

                            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
                            if hasattr(model, 'predict_proba'):
                                proba = model.predict_proba(X_window_norm)
                                confidence = np.max(proba[0])
                            else:
                                confidence = 0.5

                            if verbose and i == lookback_window:
                                print(f"  ‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ: class={predicted_class}, confidence={confidence:.3f}")
                                signals_generated += 1
                        except Exception as predict_error:
                            if verbose and i == lookback_window:
                                print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {predict_error}")
                            continue

                    else:  # –î–ª—è LSTM
                        X_window_3d = X_window.reshape(1, lookback_window, -1)

                        if verbose and i == lookback_window:
                            print(f"  üìä LSTM input shape: {X_window_3d.shape}")

                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –µ—Å–ª–∏ –µ—Å—Ç—å —Å–∫–µ–π–ª–µ—Ä
                        if scaler is not None:
                            try:
                                # –î–ª—è LSTM —Å–∫–µ–π–ª–µ—Ä –æ–∂–∏–¥–∞–µ—Ç 2D –¥–∞–Ω–Ω—ã–µ
                                X_flat = X_window_3d.reshape(1, -1)
                                X_norm_flat = scaler.transform(X_flat)
                                X_window_norm = X_norm_flat.reshape(1, lookback_window, -1)
                            except Exception as e:
                                if verbose and i == lookback_window:
                                    print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ LSTM: {e}")
                                X_window_norm = X_window_3d
                        else:
                            X_window_norm = X_window_3d

                        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                        prediction = model.predict(X_window_norm)

                        if len(prediction.shape) == 2:
                            predicted_class = np.argmax(prediction[0]) - 1
                            confidence = np.max(prediction[0])
                        else:
                            predicted_class = int(prediction[0]) - 1
                            confidence = 0.5

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏–≥–Ω–∞–ª
                    signals_df.iloc[i, signals_df.columns.get_loc('signal')] = predicted_class
                    signals_df.iloc[i, signals_df.columns.get_loc('confidence')] = confidence

                except Exception as e:
                    if verbose and i == lookback_window:
                        print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —Ç–æ—á–∫–µ {i}: {e}")
                        import traceback
                        traceback.print_exc()
                    continue

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
            valid_signals = signals_df[signals_df['signal'] != 0].copy()

            if verbose:
                print(f"  ‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(valid_signals)} —Å–∏–≥–Ω–∞–ª–æ–≤")
                if len(valid_signals) > 0:
                    long_count = len(valid_signals[valid_signals['signal'] == 1])
                    short_count = len(valid_signals[valid_signals['signal'] == -1])
                    hold_count = len(valid_signals[valid_signals['signal'] == 0])
                    print(f"  üìà –°–∏–≥–Ω–∞–ª—ã: LONG={long_count}, SHORT={short_count}, HOLD={hold_count}")

            return valid_signals

        except Exception as e:
            if verbose:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")
                import traceback
                traceback.print_exc()
            return pd.DataFrame()


    def execute_backtest(self, signals: pd.DataFrame, initial_balance: float,
                        commission: float, verbose: bool = True) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –±—ç–∫—Ç–µ—Å—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–≥–Ω–∞–ª–æ–≤
        """
        try:
            if signals.empty:
                return {'error': 'No signals to backtest'}

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            balance = initial_balance
            position = 0.0  # 0 = –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–∏, >0 = LONG, <0 = SHORT
            entry_price = 0.0
            trade_history = []
            peak_balance = initial_balance
            max_drawdown = 0.0

            for i, (timestamp, row) in enumerate(signals.iterrows()):
                try:
                    current_price = row['close']
                    signal = row['signal']
                    confidence = row['confidence']

                    # –õ–æ–≥–∏–∫–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏
                    if position == 0 and signal != 0:  # –û—Ç–∫—Ä—ã—Ç–∏–µ –ø–æ–∑–∏—Ü–∏–∏
                        position = signal  # 1 –¥–ª—è LONG, -1 –¥–ª—è SHORT
                        entry_price = current_price

                        trade = {
                            'timestamp': timestamp,
                            'type': 'LONG' if signal == 1 else 'SHORT',
                            'entry_price': entry_price,
                            'exit_price': None,
                            'entry_balance': balance,
                            'exit_balance': None,
                            'pnl': None,
                            'pnl_pct': None,
                            'duration': None,
                            'result': 'OPEN'
                        }
                        trade_history.append(trade)

                        if verbose and len(trade_history) <= 10:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 —Å–¥–µ–ª–æ–∫
                            print(f"  üìà –û—Ç–∫—Ä—ã—Ç–∞ {trade['type']} –ø–æ–∑–∏—Ü–∏—è –ø–æ ${entry_price:.4f}")

                    elif position != 0:  # –ï—Å—Ç—å –æ—Ç–∫—Ä—ã—Ç–∞—è –ø–æ–∑–∏—Ü–∏—è
                        # –†–∞—Å—á–µ—Ç P&L
                        if position == 1:  # LONG –ø–æ–∑–∏—Ü–∏—è
                            pnl_pct = (current_price - entry_price) / entry_price
                        else:  # SHORT –ø–æ–∑–∏—Ü–∏—è
                            pnl_pct = (entry_price - current_price) / entry_price

                        pnl = balance * pnl_pct

                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–æ–ø-–ª–æ—Å—Å–∞ –∏ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–∞
                        close_trade = False
                        close_reason = ""

                        if pnl_pct <= -self.stop_loss_pct:
                            close_trade = True
                            close_reason = "STOP LOSS"
                        elif pnl_pct >= self.take_profit_pct:
                            close_trade = True
                            close_reason = "TAKE PROFIT"
                        elif signal == -position:  # –ü—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–π —Å–∏–≥–Ω–∞–ª
                            close_trade = True
                            close_reason = "REVERSE SIGNAL"

                        if close_trade:
                            # –ó–∞–∫—Ä—ã—Ç–∏–µ –ø–æ–∑–∏—Ü–∏–∏
                            exit_balance = balance + pnl

                            # –£—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–º–∏—Å—Å–∏—é
                            commission_fee = exit_balance * commission
                            exit_balance -= commission_fee

                            # –û–±–Ω–æ–≤–ª—è–µ–º –±–∞–ª–∞–Ω—Å
                            balance = exit_balance

                            # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–¥–µ–ª–∫–∏
                            trade = trade_history[-1]
                            trade['exit_price'] = current_price
                            trade['exit_balance'] = exit_balance
                            trade['pnl'] = pnl
                            trade['pnl_pct'] = pnl_pct * 100
                            trade['duration'] = (timestamp - trade['timestamp']).total_seconds() / 3600  # –≤ —á–∞—Å–∞—Ö
                            trade['result'] = 'WIN' if pnl > 0 else 'LOSS'
                            trade['close_reason'] = close_reason

                            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é
                            position = 0
                            entry_price = 0.0

                            if verbose and len(trade_history) <= 10:
                                result_emoji = "‚úÖ" if pnl > 0 else "‚ùå"
                                print(f"  {result_emoji} –ó–∞–∫—Ä—ã—Ç–∞ –ø–æ–∑–∏—Ü–∏—è: P&L ${pnl:+.2f} ({pnl_pct*100:+.2f}%) - {close_reason}")

                    # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø—Ä–æ—Å–∞–¥–∫—É
                    if balance > peak_balance:
                        peak_balance = balance

                    current_drawdown = (peak_balance - balance) / peak_balance * 100
                    if current_drawdown > max_drawdown:
                        max_drawdown = current_drawdown

                except Exception as e:
                    if verbose:
                        self.log(f"Error processing signal at {timestamp}: {str(e)}", 'warning')
                    continue

            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–æ–∑–∏—Ü–∏—é –µ—Å–ª–∏ –æ–Ω–∞ –æ—Å—Ç–∞–ª–∞—Å—å –æ—Ç–∫—Ä—ã—Ç–æ–π
            if position != 0 and len(trade_history) > 0:
                last_price = signals.iloc[-1]['close']
                trade = trade_history[-1]

                if position == 1:  # LONG
                    pnl_pct = (last_price - entry_price) / entry_price
                else:  # SHORT
                    pnl_pct = (entry_price - last_price) / entry_price

                pnl = balance * pnl_pct
                exit_balance = balance + pnl
                commission_fee = exit_balance * commission
                exit_balance -= commission_fee
                balance = exit_balance

                trade['exit_price'] = last_price
                trade['exit_balance'] = exit_balance
                trade['pnl'] = pnl
                trade['pnl_pct'] = pnl_pct * 100
                trade['duration'] = (signals.index[-1] - trade['timestamp']).total_seconds() / 3600
                trade['result'] = 'WIN' if pnl > 0 else 'LOSS'
                trade['close_reason'] = 'END OF PERIOD'

                if verbose:
                    result_emoji = "‚úÖ" if pnl > 0 else "‚ùå"
                    print(f"  {result_emoji} –ü–æ–∑–∏—Ü–∏—è –∑–∞–∫—Ä—ã—Ç–∞ –≤ –∫–æ–Ω—Ü–µ –ø–µ—Ä–∏–æ–¥–∞: P&L ${pnl:+.2f} ({pnl_pct*100:+.2f}%)")

            # –†–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
            total_trades = len([t for t in trade_history if t['result'] in ['WIN', 'LOSS']])
            winning_trades = len([t for t in trade_history if t['result'] == 'WIN'])
            losing_trades = len([t for t in trade_history if t['result'] == 'LOSS'])

            win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0

            total_pnl = sum([t['pnl'] or 0 for t in trade_history])
            total_return = (balance - initial_balance) / initial_balance * 100

            winning_pnl = sum([t['pnl'] or 0 for t in trade_history if t['result'] == 'WIN'])
            losing_pnl = sum([t['pnl'] or 0 for t in trade_history if t['result'] == 'LOSS'])

            profit_factor = abs(winning_pnl / losing_pnl) if losing_pnl != 0 else float('inf')

            avg_win = np.mean([t['pnl'] or 0 for t in trade_history if t['result'] == 'WIN']) if winning_trades > 0 else 0
            avg_loss = np.mean([t['pnl'] or 0 for t in trade_history if t['result'] == 'LOSS']) if losing_trades > 0 else 0

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            results = {
                'initial_balance': initial_balance,
                'final_balance': balance,
                'total_pnl': total_pnl,
                'total_return': total_return,
                'total_trades': total_trades,
                'winning_trades': winning_trades,
                'losing_trades': losing_trades,
                'win_rate': win_rate,
                'profit_factor': profit_factor,
                'max_drawdown': max_drawdown,
                'avg_win': avg_win,
                'avg_loss': avg_loss,
                'trade_history': trade_history,
                'summary': {
                    'aggregated': {
                        'total_return': total_return,
                        'final_balance': balance,
                        'total_pnl': total_pnl,
                        'total_trades': total_trades,
                        'winning_trades': winning_trades,
                        'losing_trades': losing_trades,
                        'avg_win_rate': win_rate,
                        'profit_factor': profit_factor,
                        'max_drawdown': max_drawdown,
                        'avg_win': avg_win,
                        'avg_loss': avg_loss
                    }
                }
            }

            if verbose:
                self.log(f"Backtest completed: {total_trades} trades, Return: {total_return:.2f}%")

            return results

        except Exception as e:
            self.log(f"Error executing backtest: {str(e)}", 'error')
            return {'error': str(e)}

    def save_backtest_results(self, results: Dict[str, Any], symbol: str, model_id: Optional[str] = None):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            if 'error' in results:
                return False

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞
            if not model_id:
                models_df = self.db.get_available_models(
                    symbol=symbol,
                    active_only=True,
                    verbose=False
                )
                if not models_df.empty:
                    model_id = models_df.iloc[0]['model_id']

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            result_data = {
                'model_id': model_id or 'unknown',
                'symbol': symbol,
                'timeframe': self.state_manager.get_selected_timeframe(),
                'test_date': datetime.now(),
                'start_date': self.state_manager.get_backtest_dates()[0],
                'end_date': self.state_manager.get_backtest_dates()[1],
                'initial_balance': results['initial_balance'],
                'final_balance': results['final_balance'],
                'total_return': results['total_return'],
                'sharpe_ratio': 0,  # –ú–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
                'max_drawdown': results['max_drawdown'],
                'win_rate': results['win_rate'],
                'profit_factor': results['profit_factor'],
                'total_trades': results['total_trades'],
                'winning_trades': results['winning_trades'],
                'losing_trades': results['losing_trades'],
                'avg_win': results['avg_win'],
                'avg_loss': results['avg_loss'],
                'details': '{}'  # –ú–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–µ—Ç–∞–ª–∏ —Å–¥–µ–ª–æ–∫
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É
            self.db.save_backtest_result(result_data, verbose=self.verbose)

            return True

        except Exception as e:
            self.log(f"Error saving backtest results: {str(e)}", 'error')
            return False

    def run_comprehensive_backtest(self, symbol: str,
                                 initial_balance: float = 10000.0,
                                 commission: float = None,
                                 model_id: str = None,
                                 verbose: bool = True) -> Dict[str, Any]:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        try:
            if verbose:
                print(f"üöÄ –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∞ –¥–ª—è {symbol}")
                print(f"   –ù–∞—á–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å: ${initial_balance:,.2f}")
                if commission is not None:
                    print(f"   –ö–æ–º–∏—Å—Å–∏—è: {commission * 100:.2f}%")
                else:
                    print(f"   –ö–æ–º–∏—Å—Å–∏—è: {self.commission * 100:.2f}%")

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–º–∏—Å—Å–∏—é –µ—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞
            if commission is not None:
                self.commission = commission

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—ã –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞
            start_date, end_date = self.state_manager.get_backtest_dates()

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞
            data = self.db.get_historical_data(
                symbol=symbol,
                timeframe=self.state_manager.get_selected_timeframe(),
                start_date=start_date,
                end_date=end_date,
                verbose=verbose
            )

            if data.empty:
                if verbose:
                    print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞")
                return {'error': 'No data available for backtest'}

            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            model_info = self.get_best_model(symbol, model_id, verbose=verbose)

            if not model_info:
                if verbose:
                    print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ–¥—Ö–æ–¥—è—â–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞")
                return {'error': 'No suitable model found'}

            model, scaler = model_info

            if verbose:
                self.debug_model_features(model, scaler, verbose=verbose)

            model_type = 'unknown'

            # –î–æ–±–∞–≤—å—Ç–µ:
            # –Ø–≤–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏
            if hasattr(model, 'get_booster'):
                model_type = 'xgb'
            elif hasattr(model, 'name') and 'lstm' in str(model.name).lower():
                model_type = 'lstm'
            elif 'xgb' in str(type(model)).lower():
                model_type = 'xgb'
            elif 'lstm' in str(type(model)).lower():
                model_type = 'lstm'
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ –¥—Ä—É–≥–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
                try:
                    import xgboost
                    if isinstance(model, xgboost.XGBClassifier):
                        model_type = 'xgb'
                except:
                    pass

                try:
                    import tensorflow as tf
                    if isinstance(model, tf.keras.Model):
                        model_type = 'lstm'
                except:
                    pass

            if verbose:
                print(f"  ü§ñ –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω —Ç–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            preprocessed_data = self.prepare_backtest_data(
                data, model_type=model_type, verbose=verbose
            )

            if preprocessed_data.empty:
                if verbose:
                    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞")
                return {'error': 'Failed to prepare data for backtest'}

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
            signals = self.generate_backtest_signals_simple(
                preprocessed_data, model, scaler, model_type, verbose=verbose
            )

            if signals.empty:
                if verbose:
                    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–∏–≥–Ω–∞–ª—ã")
                return {'error': 'Failed to generate signals'}

            # –í—ã–ø–æ–ª–Ω—è–µ–º –±—ç–∫—Ç–µ—Å—Ç
            results = self.execute_backtest(
                signals=signals,
                initial_balance=initial_balance,
                commission=self.commission,
                verbose=verbose
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if results and 'error' not in results:
                self.save_backtest_results(results, symbol, model_id)

                if verbose:
                    print("‚úÖ –ë—ç–∫—Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                    print(f"   –ö–æ–Ω–µ—á–Ω—ã–π –±–∞–ª–∞–Ω—Å: ${results['final_balance']:,.2f}")
                    print(f"   –û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {results['total_return']:.2f}%")
                    print(f"   Win Rate: {results['win_rate']:.1f}%")

            return results

        except Exception as e:
            error_msg = f"Error in backtest: {str(e)}"
            if verbose:
                print(f"‚ùå {error_msg}")
                import traceback
                traceback.print_exc()
            return {'error': error_msg}

    def get_model_features(self, model: Any, verbose: bool = True) -> List[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π –∏–∑ –º–æ–¥–µ–ª–∏
        """
        try:
            feature_columns = None

            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ñ–∏—á–∏ –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –º–æ–¥–µ–ª–∏
            if hasattr(model, 'base_feature_names'):
                return model.base_feature_names
            elif hasattr(model, '_features'):
                return model._features
            elif hasattr(model, 'feature_names'):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ª–∏ —ç—Ç–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏ —Å –ª–∞–≥–∞–º–∏
                feature_names = model.feature_names
                if isinstance(feature_names, list) and len(feature_names) > 0:
                    # –ï—Å–ª–∏ –ø–µ—Ä–≤—ã–π —Ñ–∏—á —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–∞–≥, –∏–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏
                    if any('_t-' in feature for feature in feature_names):
                        base_features = set()
                        for feature in feature_names:
                            if '_t-' in feature:
                                base_feature = feature.split('_t-')[0]
                                base_features.add(base_feature)
                        return list(base_features)
                    else:
                        return feature_names

            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏
            if hasattr(model, 'get_booster'):
                booster = model.get_booster()
                if hasattr(booster, 'feature_names'):
                    return booster.feature_names

            return None

        except Exception as e:
            if verbose:
                print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∏—á–µ–π –∏–∑ –º–æ–¥–µ–ª–∏: {e}")
            return None

    def debug_model_features(self, model: Any, scaler: Any, verbose: bool = True):
        """
        –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ñ–∏—á–µ–π –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä–∞
        """
        if verbose:
            print(f"\nüîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ú–û–î–ï–õ–ò:")

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
            if hasattr(model, 'feature_names'):
                print(f"  üìã –§–∏—á–∏ –≤ –º–æ–¥–µ–ª–∏ (model.feature_names): {len(model.feature_names)}")
                if isinstance(model.feature_names, list):
                    print(f"  –ü–µ—Ä–≤—ã–µ 10: {model.feature_names[:10]}")

            if hasattr(model, 'base_feature_names'):
                print(f"  üìã –ë–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏ (model.base_feature_names): {len(model.base_feature_names)}")
                print(f"  {model.base_feature_names}")

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∫–µ–π–ª–µ—Ä–µ
            if scaler is not None:
                print(f"  üî¢ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∫–µ–π–ª–µ—Ä–µ:")
                if hasattr(scaler, 'n_features_in_'):
                    print(f"    –û–∂–∏–¥–∞–µ—Ç —Ñ–∏—á–µ–π: {scaler.n_features_in_}")

                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ñ–∏—á–∏ —Å–∫–µ–π–ª–µ—Ä–∞
                if hasattr(scaler, 'feature_names_in_'):
                    print(f"    –§–∏—á–∏ —Å–∫–µ–π–ª–µ—Ä–∞: {len(scaler.feature_names_in_)}")
                    print(f"    –ü–µ—Ä–≤—ã–µ 10: {scaler.feature_names_in_[:10]}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π
            if hasattr(model, 'feature_names') and scaler is not None and hasattr(scaler, 'n_features_in_'):
                model_features_count = len(model.feature_names) if isinstance(model.feature_names, list) else 0
                if model_features_count > 0:
                    print(f"  ‚öñÔ∏è  –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∏—á–µ–π:")
                    print(f"    –ú–æ–¥–µ–ª—å: {model_features_count} —Ñ–∏—á–µ–π")
                    print(f"    –°–∫–µ–π–ª–µ—Ä: {scaler.n_features_in_} —Ñ–∏—á–µ–π")

                    if model_features_count != scaler.n_features_in_:
                        print(f"  ‚ùå –ù–ï–°–û–í–ü–ê–î–ï–ù–ò–ï! –ú–æ–¥–µ–ª—å –∏ —Å–∫–µ–π–ª–µ—Ä –æ–±—É—á–µ–Ω—ã –Ω–∞ —Ä–∞–∑–Ω–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —Ñ–∏—á–µ–π!")
                        print(f"  ‚ö†Ô∏è  –≠—Ç–æ –æ—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞ –æ—à–∏–±–∫–∏!")

    def debug_data_preparation(self, data: pd.DataFrame, feature_columns: List[str],
                               lookback_window: int, model_type: str, verbose: bool = True):
        """
        –î–µ—Ç–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        """
        if verbose:
            print(f"\nüî¨ –î–ï–¢–ê–õ–¨–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–û–î–ì–û–¢–û–í–ö–ò –î–ê–ù–ù–´–•:")
            print(f"  üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(data)} —Å—Ç—Ä–æ–∫, {len(data.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            print(f"  üîç –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ–∏—á–∏: {len(feature_columns)}")
            print(f"  üìê Lookback window: {lookback_window}")
            print(f"  ü§ñ –¢–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ —Å —Ñ–∏—á–∞–º–∏
            if len(data) > 0 and len(feature_columns) > 0:
                sample_data = data[feature_columns].head(3)
                print(f"  üìã –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏):")
                for idx, row in sample_data.iterrows():
                    print(f"    {idx}: {[round(val, 4) for val in row.values[:5]]}...")

            # –î–ª—è XGBoost –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
            if 'xgb' in model_type.lower():
                print(f"\n  üéØ –û–ñ–ò–î–ê–ï–ú–´–ô –§–û–†–ú–ê–¢ –î–õ–Ø XGBOOST:")
                print(f"    –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: –æ–∫–Ω–æ {lookback_window} √ó {len(feature_columns)} —Ñ–∏—á–µ–π")
                print(
                    f"    –ü–æ—Å–ª–µ flatten: 1 √ó {lookback_window * len(feature_columns)} = 1 √ó {lookback_window * len(feature_columns)}")

                # –ü—Ä–∏–º–µ—Ä –¥–ª—è –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏
                if len(data) >= lookback_window:
                    window_data = data.iloc[:lookback_window][feature_columns]
                    print(f"\n  üìä –ü–†–ò–ú–ï–† –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–Ø:")
                    print(f"    –û–∫–Ω–æ –¥–∞–Ω–Ω—ã—Ö shape: {window_data.shape}")
                    print(f"    Flattened shape: {window_data.values.flatten().reshape(1, -1).shape}")