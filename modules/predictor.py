"""
–ú–æ–¥—É–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
"""

import numpy as np
import pandas as pd
import logging
from datetime import datetime, timedelta
from typing import Dict, Optional, Any, Tuple
from config import config
from modules.database import Database
from modules.preprocessor import DataPreprocessor
from modules.trainer import ModelTrainer
from modules.state_manager import state_manager


class SignalPredictor:
    def __init__(self, verbose: bool = True):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—è"""
        self.verbose = verbose
        self.setup_logging()
        self.db = Database(verbose=verbose)
        self.preprocessor = DataPreprocessor(verbose=verbose)
        self.trainer = ModelTrainer(verbose=verbose)

    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        self.logger = logging.getLogger(__name__)
        if self.verbose:
            self.logger.setLevel(logging.INFO)
        else:
            self.logger.setLevel(logging.WARNING)

    def log(self, message: str, level: str = 'info'):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        if self.verbose:
            if level == 'info':
                self.logger.info(message)
            elif level == 'error':
                self.logger.error(message)
            elif level == 'warning':
                self.logger.warning(message)

    def get_best_model_id(self, symbol: str, preferred_type: str = None) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ ID –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
        try:
            models_df = self.db.get_available_models(
                symbol=symbol,
                active_only=True,
                verbose=False
            )

            if not models_df.empty:
                # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π —Ç–∏–ø
                if preferred_type:
                    type_models = models_df[models_df['model_type'].str.contains(preferred_type)]
                    if not type_models.empty:
                        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å –Ω—É–∂–Ω–æ–≥–æ —Ç–∏–ø–∞
                        return type_models.iloc[0]['model_id']

                # –ò–Ω–∞—á–µ –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é XGBoost –º–æ–¥–µ–ª—å (–æ–Ω–∞ –±—ã—Å—Ç—Ä–µ–µ)
                xgb_models = models_df[models_df['model_type'].str.contains('xgb')]
                if not xgb_models.empty:
                    return xgb_models.iloc[0]['model_id']

                # –ò–Ω–∞—á–µ –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å –ª—é–±–æ–≥–æ —Ç–∏–ø–∞
                return models_df.iloc[0]['model_id']

            return None

        except Exception as e:
            self.log(f"Error getting best model: {e}", 'error')
            return None

    def prepare_data_for_xgboost_prediction(self, data: pd.DataFrame, model: Any,
                                          lookback_window: int, verbose: bool = True) -> np.ndarray:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è XGBoost –º–æ–¥–µ–ª–∏
        —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ñ–∏—á–µ–π
        """
        try:
            if data.empty or model is None:
                return np.array([])

            # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏ –∏–∑ –º–æ–¥–µ–ª–∏
            if hasattr(model, 'base_feature_names'):
                base_features = model.base_feature_names
            elif hasattr(model, 'feature_names'):
                # –ï—Å–ª–∏ —ç—Ç–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ —Å –ª–∞–≥–∞–º–∏
                feature_names = model.feature_names
                if feature_names and any('_t-' in str(f) for f in feature_names[:10]):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –±–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏
                    base_features = set()
                    for feature in feature_names:
                        if isinstance(feature, str) and '_t-' in feature:
                            base_feature = feature.split('_t-')[0]
                            base_features.add(base_feature)
                        else:
                            base_features.add(str(feature))
                    base_features = list(base_features)
                else:
                    base_features = feature_names
            else:
                # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –Ω–∞–±–æ—Ä —Ñ–∏—á–µ–π
                base_features = ['open', 'high', 'low', 'close', 'volume', 'returns']
                tech_indicators = [col for col in data.columns
                                  if any(indicator in col.lower() for indicator in
                                         ['sma', 'ema', 'rsi', 'macd', 'bb', 'atr', 'obv', 'adx', 'stoch',
                                          'williams'])]
                base_features += tech_indicators

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ —Ñ–∏—á–∏ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
            available_features = [f for f in base_features if f in data.columns]
            missing_features = [f for f in base_features if f not in data.columns]

            if verbose:
                print(f"  üîß XGBoost: —Ç—Ä–µ–±—É–µ—Ç—Å—è {len(base_features)} —Ñ–∏—á–µ–π")
                print(f"  üìä –î–æ—Å—Ç—É–ø–Ω–æ –≤ –¥–∞–Ω–Ω—ã—Ö: {len(available_features)} —Ñ–∏—á–µ–π")
                if missing_features:
                    print(f"  ‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç {len(missing_features)} —Ñ–∏—á–µ–π")

            # –°–æ–∑–¥–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ–∏—á–∏ —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            for feature in missing_features:
                data[feature] = 0.0

            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —É –Ω–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
            if len(data) < lookback_window:
                if verbose:
                    print(f"  ‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(data)} < {lookback_window}")
                return np.array([])

            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ lookback_window –∑–Ω–∞—á–µ–Ω–∏–π
            window_data = data.iloc[-lookback_window:][base_features].values

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è XGBoost (2D)
            X_window_flat = window_data.flatten().reshape(1, -1)

            if verbose:
                print(f"  üìè –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞: {window_data.shape} -> {X_window_flat.shape}")
                print(f"  üî¢ –í—Å–µ–≥–æ —Ñ–∏—á–µ–π: {X_window_flat.shape[1]}")

            return X_window_flat

        except Exception as e:
            self.log(f"Error preparing data for XGBoost prediction: {e}", 'error')
            return np.array([])

    def calculate_indicators_for_prediction(self, data: pd.DataFrame, model_type: str,
                                          verbose: bool = True) -> pd.DataFrame:
        """
        –†–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –Ω—É–∂–Ω—ã—Ö —Ñ–∏—á–µ–π
        """
        try:
            if data.empty:
                return data

            if verbose:
                print(f"  üìà –†–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π —Ä–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            data_with_indicators = self.preprocessor.calculate_all_indicators(
                data, verbose=verbose
            )

            if verbose:
                print(f"  üìä –ë–∞–∑–æ–≤—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {len(data_with_indicators.columns)}")

            # –î–ª—è LSTM –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö 55 —Ñ–∏—á–µ–π
            if 'lstm' in model_type.lower():
                if verbose:
                    print(f"  ü§ñ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á–µ–π –¥–ª—è LSTM (—Ç—Ä–µ–±—É–µ—Ç—Å—è 55)")

                # –°–ø–∏—Å–æ–∫ –í–°–ï–• —Ñ–∏—á–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤ LSTM –º–æ–¥–µ–ª–∏
                all_possible_features = [
                    # –û—Å–Ω–æ–≤–Ω—ã–µ OHLCV
                    'open', 'high', 'low', 'close', 'volume',

                    # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
                    'SMA_20', 'SMA_50', 'SMA_100', 'SMA_200',
                    'EMA_12', 'EMA_26', 'EMA_50',

                    # RSI
                    'RSI_14', 'RSI_7',

                    # Stochastic
                    'STOCH_K', 'STOCH_D',

                    # MACD
                    'MACD', 'MACD_SIGNAL', 'MACD_DIFF',

                    # Bollinger Bands
                    'BB_UPPER', 'BB_MIDDLE', 'BB_LOWER', 'BB_WIDTH', 'BB_PCT',

                    # –î—Ä—É–≥–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                    'ATR_14', 'PSAR', 'CCI_20', 'AO', 'WILLIAMS_R',
                    'ROC_10', 'ROC_20', 'MFI_14', 'OBV',

                    # Ichimoku
                    'ICHIMOKU_CONVERSION', 'ICHIMOKU_BASE', 'ICHIMOKU_A', 'ICHIMOKU_B',

                    # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Ñ–∏—á–∏
                    'RETURNS', 'LOG_RETURNS', 'VOLATILITY_20', 'VOLUME_MA_20',
                    'PRICE_RANGE', 'BODY_SIZE',

                    # –°–∏–≥–Ω–∞–ª—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
                    'RSI_SIGNAL', 'MACD_CROSS', 'BB_SIGNAL', 'TECH_TARGET',

                    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ (–±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –ø–æ–∑–∂–µ)
                ]

                # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –±–∞–∑–æ–≤—ã–µ 5 —Ñ–∏—á–µ–π
                if not all(col in data_with_indicators.columns for col in ['open', 'high', 'low', 'close', 'volume']):
                    if verbose:
                        print(f"  ‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –±–∞–∑–æ–≤—ã–µ OHLCV —Ñ–∏—á–∏")
                    return data_with_indicators

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ —Ñ–∏—á–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
                existing_features = [f for f in all_possible_features if f in data_with_indicators.columns]
                missing_features = [f for f in all_possible_features if f not in data_with_indicators.columns]

                if verbose:
                    print(f"  ‚úÖ –ï—Å—Ç—å —Ñ–∏—á–µ–π: {len(existing_features)}")
                    if missing_features:
                        print(f"  ‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç: {len(missing_features)} —Ñ–∏—á–µ–π")
                        print(f"     –ü—Ä–∏–º–µ—Ä: {missing_features[:5]}")

                # –°–æ–∑–¥–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ–∏—á–∏ —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                for feature in missing_features:
                    data_with_indicators[feature] = 0.0
                    if verbose and len(missing_features) <= 10:
                        print(f"     ‚ûï –°–æ–∑–¥–∞–Ω–∞ —Ñ–∏—á–∞: {feature}")

                # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å - datetime
                temporal_features_added = False
                if hasattr(data_with_indicators.index, 'hour'):
                    data_with_indicators['HOUR'] = data_with_indicators.index.hour
                    data_with_indicators['DAY_OF_WEEK'] = data_with_indicators.index.dayofweek
                    data_with_indicators['MONTH'] = data_with_indicators.index.month
                    temporal_features_added = True
                else:
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏
                    data_with_indicators['HOUR'] = 0
                    data_with_indicators['DAY_OF_WEEK'] = 0
                    data_with_indicators['MONTH'] = 0

                # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –∏–∑ 55 —Ñ–∏—á–µ–π
                final_features = all_possible_features + ['HOUR', 'DAY_OF_WEEK', 'MONTH']

                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —É –Ω–∞—Å –≤—Å–µ —Ñ–∏—á–∏
                for feature in final_features:
                    if feature not in data_with_indicators.columns:
                        data_with_indicators[feature] = 0.0

                # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Ñ–∏—á–∏ –∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
                data_with_indicators = data_with_indicators[final_features]

                if verbose:
                    print(f"  ‚úÖ –ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π –¥–ª—è LSTM: {len(data_with_indicators.columns)}")
                    print(f"  üìä –ü–µ—Ä–≤—ã–µ 10 —Ñ–∏—á–µ–π: {list(data_with_indicators.columns)[:10]}")

            return data_with_indicators

        except Exception as e:
            self.log(f"Error calculating indicators for prediction: {e}", 'error')
            return data

    def _get_lstm_signal(self, symbol: str, model, scaler, model_id: str, model_type: str,
                        data_with_indicators: pd.DataFrame, verbose: bool = True) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è LSTM –º–æ–¥–µ–ª–∏"""
        try:
            if verbose:
                print(f"  ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–∞ LSTM –¥–ª—è {symbol}")
                print(f"  üìä –î–∞–Ω–Ω—ã–µ: {len(data_with_indicators)} —Å—Ç—Ä–æ–∫, {len(data_with_indicators.columns)} –∫–æ–ª–æ–Ω–æ–∫")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π
            current_features = len(data_with_indicators.columns)

            if verbose:
                print(f"  üîç –¢–µ–∫—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π: {current_features}")
                print(f"  üéØ –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π: 55")

            # –ï—Å–ª–∏ —Ñ–∏—á–µ–π –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ
            if current_features < 55:
                missing = 55 - current_features
                if verbose:
                    print(f"  ‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ñ–∏—á–µ–π: –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å {missing}")

                # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ —Ñ–∏—á–∏
                for i in range(missing):
                    col_name = f'MISSING_{i}'
                    data_with_indicators[col_name] = 0.0

                if verbose:
                    print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {missing} —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö —Ñ–∏—á–µ–π")

            # –ï—Å–ª–∏ —Ñ–∏—á–µ–π —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ, –æ–±—Ä–µ–∑–∞–µ–º
            elif current_features > 55:
                if verbose:
                    print(f"  ‚ö†Ô∏è  –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ñ–∏—á–µ–π: {current_features}, –æ–±—Ä–µ–∑–∞–µ–º –¥–æ 55")
                # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–µ 55 –∫–æ–ª–æ–Ω–æ–∫
                cols_to_keep = list(data_with_indicators.columns)[:55]
                data_with_indicators = data_with_indicators[cols_to_keep]

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if verbose:
                print(f"  üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")

            X_sequence = self.preprocessor.prepare_features_for_prediction(
                df=data_with_indicators,
                lookback_window=config.model.LOOKBACK_WINDOW,
                verbose=verbose
            )

            if len(X_sequence) == 0:
                if verbose:
                    print(f"  ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
                return {'signal': 'HOLD', 'reason': 'Insufficient data for prediction'}

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π
            final_features = X_sequence.shape[-1]

            if verbose:
                print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {X_sequence.shape}")
                print(f"  üî¢ –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π: {final_features}")

            # –î–≤–æ–π–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –µ—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ 55, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º
            if final_features != 55:
                if verbose:
                    print(f"  ‚ö†Ô∏è  –í—Å–µ –µ—â–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {final_features} != 55")
                    print(f"  üîß –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫—É...")

                if final_features < 55:
                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–µ–≤—ã–µ —Ñ–∏—á–∏
                    diff = 55 - final_features
                    zeros = np.zeros((X_sequence.shape[0], X_sequence.shape[1], diff))
                    X_sequence = np.concatenate([X_sequence, zeros], axis=-1)
                    if verbose:
                        print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {diff} –Ω—É–ª–µ–≤—ã—Ö —Ñ–∏—á–µ–π")
                else:
                    # –û–±—Ä–µ–∑–∞–µ–º –ª–∏—à–Ω–∏–µ —Ñ–∏—á–∏
                    X_sequence = X_sequence[:, :, :55]
                    if verbose:
                        print(f"  ‚úÖ –û–±—Ä–µ–∑–∞–Ω–æ –¥–æ 55 —Ñ–∏—á–µ–π")

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            if scaler is not None:
                try:
                    X_normalized, _ = self.preprocessor.normalize_features(
                        X_sequence, fit=False, scaler=scaler, verbose=verbose
                    )
                    if verbose:
                        print(f"  ‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã")
                except Exception as e:
                    if verbose:
                        print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
                    X_normalized = X_sequence
            else:
                X_normalized = X_sequence
                if verbose:
                    print(f"  ‚ö†Ô∏è  –°–∫–∞–ª–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            if verbose:
                print(f"  ü§ñ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è LSTM...")

            predictions = model.predict(X_normalized, verbose=0)

            if verbose:
                print(f"  üìä –ü–æ–ª—É—á–µ–Ω—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {predictions.shape}")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤
            if len(predictions.shape) == 2 and predictions.shape[1] == 3:
                # –ú—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å 3 –∫–ª–∞—Å—Å–∞–º–∏
                predicted_class = np.argmax(predictions[0]) - 1  # -1, 0, 1
                confidence = np.max(predictions[0])

                probabilities = {
                    'SHORT': float(predictions[0][0]),
                    'HOLD': float(predictions[0][1]),
                    'LONG': float(predictions[0][2])
                }
            elif len(predictions.shape) == 2 and predictions.shape[1] == 1:
                # –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏—è
                predicted_value = predictions[0][0]
                if predicted_value > 0.5:
                    predicted_class = 1  # LONG
                    confidence = predicted_value
                elif predicted_value < -0.5:
                    predicted_class = -1  # SHORT
                    confidence = abs(predicted_value)
                else:
                    predicted_class = 0  # HOLD
                    confidence = 0.5

                probabilities = {
                    'SHORT': max(0, 1 - predicted_value) / 2,
                    'HOLD': 0.5,
                    'LONG': max(0, predicted_value) / 2
                }
            else:
                # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                predicted_class = 0
                confidence = 0.0
                probabilities = {'SHORT': 0, 'HOLD': 1, 'LONG': 0}

            if verbose:
                print(f"  üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: –∫–ª–∞—Å—Å {predicted_class}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.2%}")
                print(f"  üìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: SHORT={probabilities['SHORT']:.2%}, "
                      f"HOLD={probabilities['HOLD']:.2%}, LONG={probabilities['LONG']:.2%}")

            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –≤ —Å–∏–≥–Ω–∞–ª
            signal_map = {-1: 'SHORT', 0: 'HOLD', 1: 'LONG'}
            signal = signal_map.get(predicted_class, 'HOLD')

            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = {
                'symbol': symbol,
                'signal': signal,
                'timestamp': datetime.now(),
                'price': float(data_with_indicators['close'].iloc[-1]) if 'close' in data_with_indicators.columns else 0.0,
                'model_id': model_id,
                'model_type': model_type,
                'confidence': float(confidence),
                'probabilities': probabilities,
                'reason': 'AI model prediction'
            }

            self.log(f"Generated LSTM signal for {symbol}: {signal} (confidence: {confidence:.2f})")
            return result

        except Exception as e:
            self.log(f"Error in LSTM signal generation: {e}", 'error')
            return {'symbol': symbol, 'signal': 'HOLD', 'reason': f'LSTM Error: {str(e)}'}

    def _get_xgboost_signal(self, symbol: str, model, scaler, model_id: str, model_type: str,
                           data_with_indicators: pd.DataFrame, verbose: bool = True) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è XGBoost –º–æ–¥–µ–ª–∏"""
        try:
            if verbose:
                print(f"  ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–∞ XGBoost –¥–ª—è {symbol}")

            # –î–ª—è XGBoost - —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            X_window_flat = self.prepare_data_for_xgboost_prediction(
                data_with_indicators, model, config.model.LOOKBACK_WINDOW, verbose
            )

            if X_window_flat.size == 0:
                return {'signal': 'HOLD', 'reason': 'Failed to prepare data for XGBoost prediction'}

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∏—á–µ–π
            if hasattr(model, 'n_features_in_'):
                expected_features = model.n_features_in_
            elif hasattr(model, 'feature_names'):
                expected_features = len(model.feature_names)
            else:
                expected_features = X_window_flat.shape[1]

            if X_window_flat.shape[1] != expected_features:
                if verbose:
                    print(f"  ‚ö†Ô∏è  –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–∏—á–µ–π: –¥–∞–Ω–Ω—ã–µ {X_window_flat.shape[1]}, –º–æ–¥–µ–ª—å {expected_features}")
                    print(f"  üîß –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å...")

                # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
                if X_window_flat.shape[1] < expected_features:
                    # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
                    diff = expected_features - X_window_flat.shape[1]
                    zeros = np.zeros((1, diff))
                    X_window_flat = np.hstack([X_window_flat, zeros])
                    if verbose:
                        print(f"  ‚úÖ –î–æ–ø–æ–ª–Ω–µ–Ω–æ –Ω—É–ª—è–º–∏: +{diff} —Ñ–∏—á–µ–π")
                else:
                    # –û–±—Ä–µ–∑–∞–µ–º
                    X_window_flat = X_window_flat[:, :expected_features]
                    if verbose:
                        print(f"  ‚úÖ –û–±—Ä–µ–∑–∞–Ω–æ: {X_window_flat.shape[1]} —Ñ–∏—á–µ–π")

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å —Å–∫–µ–π–ª–µ—Ä
            if scaler is not None:
                try:
                    X_normalized = scaler.transform(X_window_flat)
                    if verbose:
                        print(f"  ‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã")
                except Exception as e:
                    if verbose:
                        print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
                    X_normalized = X_window_flat
            else:
                X_normalized = X_window_flat

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            if hasattr(model, 'predict_proba'):
                proba = model.predict_proba(X_normalized)[0]
                predicted_class = model.predict(X_normalized)[0]
                confidence = np.max(proba)

                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–ª–∞—Å—Å [0,1,2] -> [-1,0,1]
                predicted_class = int(predicted_class) - 1

                probabilities = {
                    'SHORT': float(proba[0]),
                    'HOLD': float(proba[1]),
                    'LONG': float(proba[2])
                }
            else:
                predicted_class = model.predict(X_normalized)[0]
                predicted_class = int(predicted_class) - 1
                confidence = 1.0
                probabilities = {'SHORT': 0, 'HOLD': 0, 'LONG': 0}
                probabilities[['SHORT', 'HOLD', 'LONG'][predicted_class + 1]] = 1.0

            if verbose:
                print(f"  ü§ñ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: –∫–ª–∞—Å—Å {predicted_class}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.2%}")

            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –≤ —Å–∏–≥–Ω–∞–ª
            signal_map = {-1: 'SHORT', 0: 'HOLD', 1: 'LONG'}
            signal = signal_map.get(predicted_class, 'HOLD')

            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = {
                'symbol': symbol,
                'signal': signal,
                'timestamp': datetime.now(),
                'price': float(data_with_indicators['close'].iloc[-1]) if 'close' in data_with_indicators.columns else 0.0,
                'model_id': model_id,
                'model_type': model_type,
                'confidence': float(confidence),
                'probabilities': probabilities,
                'reason': 'AI model prediction'
            }

            self.log(f"Generated XGBoost signal for {symbol}: {signal} (confidence: {confidence:.2f})")
            return result

        except Exception as e:
            self.log(f"Error in XGBoost signal generation: {e}", 'error')
            return {'symbol': symbol, 'signal': 'HOLD', 'reason': f'XGBoost Error: {str(e)}'}

    def get_signal(self, symbol: str = None, model_id: str = None, verbose: bool = True) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞—Ä—ã
        """
        try:
            if symbol is None:
                symbol = state_manager.get_selected_symbol()
                if not symbol:
                    return {'signal': 'HOLD', 'reason': 'No symbol selected'}

            self.log(f"Generating signal for {symbol}")

            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
            if model_id:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
                model, scaler, model_type = self.load_specific_model_by_id(model_id, symbol)
                if model is None:
                    return {'signal': 'HOLD', 'reason': f'Failed to load model {model_id}'}
            else:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                model_id = self.get_best_model_id(symbol)
                if model_id is None:
                    return {'signal': 'HOLD', 'reason': 'No trained models available'}

                model, scaler = self.trainer.load_model(model_id, verbose=verbose)
                if model is None:
                    return {'signal': 'HOLD', 'reason': 'Failed to load model'}

                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
                all_models_df = self.db.get_available_models(
                    symbol=symbol,
                    active_only=True,
                    verbose=False
                )
                if all_models_df.empty:
                    return {'signal': 'HOLD', 'reason': 'No models found for symbol'}

                model_row = all_models_df[all_models_df['model_id'] == model_id]
                if model_row.empty:
                    return {'signal': 'HOLD', 'reason': f'Model {model_id} not found'}

                model_type = model_row.iloc[0]['model_type']

            # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            end_date = datetime.now()
            # –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤ –±–µ—Ä–µ–º –ë–û–õ–¨–®–ï –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —É—Å–ø–µ–ª–∏ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å—Å—è
            start_date = end_date - timedelta(days=180)  # 6 –º–µ—Å—è—Ü–µ–≤ –¥–∞–Ω–Ω—ã—Ö

            if verbose:
                print(f"  üìÖ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å {start_date.date()} –ø–æ {end_date.date()}")

            data = self.db.get_historical_data(
                symbol=symbol,
                timeframe=state_manager.get_selected_timeframe(),
                start_date=start_date,
                end_date=end_date,
                verbose=verbose
            )

            if data.empty or len(data) < config.model.LOOKBACK_WINDOW:
                if verbose:
                    print(f"  ‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(data)} —Å—Ç—Ä–æ–∫ < {config.model.LOOKBACK_WINDOW}")
                return {'signal': 'HOLD', 'reason': 'Insufficient data'}

            if verbose:
                print(f"  üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(data)} —Å—Ç—Ä–æ–∫")
                print(f"  ü§ñ –¢–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")

            # –†–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –Ω—É–∂–Ω—ã—Ö —Ñ–∏—á–µ–π
            data_with_indicators = self.calculate_indicators_for_prediction(
                data, model_type, verbose=verbose
            )

            if data_with_indicators.empty:
                return {'signal': 'HOLD', 'reason': 'Failed to calculate indicators'}

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏
            if 'lstm' in model_type.lower():
                return self._get_lstm_signal(symbol, model, scaler, model_id, model_type,
                                            data_with_indicators, verbose)
            elif 'xgb' in model_type.lower():
                return self._get_xgboost_signal(symbol, model, scaler, model_id, model_type,
                                               data_with_indicators, verbose)
            else:
                return {'signal': 'HOLD', 'reason': 'Unknown model type'}

        except Exception as e:
            self.log(f"Error generating signal for {symbol}: {e}", 'error')
            import traceback
            self.log(f"Traceback: {traceback.format_exc()}", 'error')
            return {'symbol': symbol, 'signal': 'HOLD', 'reason': f'Error: {str(e)}'}

    def load_specific_model_by_id(self, model_id: str, symbol: str = None) -> Tuple[Any, Any, str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ –ø–æ ID"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–∏–º–≤–æ–ª–∞
            if symbol:
                all_models_df = self.db.get_available_models(
                    symbol=symbol,
                    active_only=True,
                    verbose=False
                )
            else:
                all_models_df = self.db.get_available_models(
                    active_only=True,
                    verbose=False
                )

            if all_models_df.empty:
                return None, None, None

            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å –ø–æ ID
            model_row = all_models_df[all_models_df['model_id'] == model_id]
            if model_row.empty:
                return None, None, None

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            model, scaler = self.trainer.load_model(model_id, verbose=self.verbose)
            model_type = model_row.iloc[0]['model_type']

            return model, scaler, model_type

        except Exception as e:
            self.log(f"Error loading specific model {model_id}: {e}", 'error')
            return None, None, None